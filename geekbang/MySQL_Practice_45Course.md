"--------------------------------------------------------"

           极客时间 林晓斌 《MySQL 实战 45 讲》

"--------------------------------------------------------"

"""01| 基础架构: 一条 SQL 查询语句是如何执行的？"""

    1、MySQL 组成:
    
        MySQL 可以分为 Server 层和存储引擎层两部分。
        
        Server 层包括：连接器、查询缓存(MySQL 8.0删除缓存模块)、分析器、优化器、执行器等。
        涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)
        所有跨存储引擎的功能都在这一层实现，比如：存储过程、触发器、视图等。
        
        存储引擎：负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等
        多个存储引擎。MySQL 5.5 默认 InnoDB 存储引擎。    
        不同的存储引擎共用一个 Server 层。也就是从连接器到执行器的部分。
        
    2、连接器:
        
        连接器负责跟客户端建立连接、获取权限、维持和管理连接。
        连接命令一般是这么写：
            
            mysql -h$ip -P$port -u$user -p
            
        数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。
        短连接则是指每次执行完很少的几次查询就断开连接，下一次查询再重新建立一个。
        
        建立连接的过程比较复杂，尽量减少建立连接的动作，也就是尽量使用长连接。
        但是，全部使用长连接，MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程
        中临时使用的内存是管理在连接对象里面的，这些资源会在断开连接的时候才释放。
        如果长连接积累下来，可能导致内存占用太大，被系统强行杀掉（OOM）,从现象
        上看就是 MySQL 异常重启。
        
        解决办法：
        
            a. 定期断开长连接。
            
            b. 如果你使用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过
                执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新
                做权限验证，但是会恢复到刚刚建完时的状态。
                
    3、查询缓存：
    
        MySQL 拿到一个请求后，会先到查询缓存看看，之前是不是执行过这条语句，之前执行过的语句及结果
        可能会以 key-value 对的形式被直接缓存到内存中。key 是查询的语句。value是查询的结果。
        如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结构会被存入查询缓存中。
        
        但是建议不要使用缓存，往往弊大于利。
        MySQL 将参数 query_cache_type 设置成 DEMAND, 这样对于默认的 SQL 语句都不使用查询缓存。
        
        MySQL8.0 版本直接将查询缓存整块功能删掉了。
        
    4、分析器：
    
        分析器 先会做“词法分析”。你输入的由多个字符串和空格组成的一条 SQL 语句， MySQL 需要识别
        出里面的字符串分别是什么，代表什么。
        
        然后是“语法分析”。根据“词法分析”结果，语法分析会根据语法分析规则，判断是否满足 MySQL 语法。
        
    5、优化器：
    
        经过 分析器，MySQL 就知道你要做什么了，在开始执行之前，还要经过优化器的处理。
        
        优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多个关联(join)
        的时候，决定各个表的连接顺序。
        
        mysql > select * from t1 join t2 using(ID) where t1.c = 10 and t2.d = 20;
        
        即可以先从表 t1 里面取出 c = 10 的记录的 ID 值，再根据 ID 值关联到表 t2, 再判断 t2 里面 d 的值是否等于 20.        
        也可以先从表 t2 里面取出 d = 20 的记录的 ID 值，再根据 ID 值关联到表 t1, 再判断 t1 里面 c 的值是否等于 10.

        优化器阶段完成后，这个语句的执行方案就确定下来了。然后进行执行器阶段。                     
            
    6. 执行器：
    
        mysql> select *from T where ID = 10;
        
        开始执行的时候，要判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。
        如果有权限，就开打表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。
        
        比如上面的例子表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：
        
            a. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，
                如果是则将这行存在的结果集中;
                
            b. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
            
            c. 执行器将上述遍历过程中所有满足条件的行组成记录集作为结果集返回给客户端。
            
        至此，这个语句就执行完成了。
        
        对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，
        之后循环取“满足条件的下一行”这个接口，这些接口都是在引擎中定义好的。
        
        你会在数据库慢日志看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。
        这个值就是在执行器每次调用引擎获取数据行的时候累加的。
        
        
"""02| 日志系统： 一条 SQL 更新语句是如何执行的"""        

    1、一条更新语句的执行流程是怎么样的呢？
        
        表的创建语句，这个表有一个主键 ID 和一个整型字段 c:
            mysql> create table T(ID int primary key, c int);
        
        如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：
            mysql> update T set c = c+1 where ID=2;
    
        更新语句的执行流程和查询流程一样，都有经过 连接器、清除缓存(语句会把表T上所有的缓存结果都清空)，
        分析器、执行器。                    
        与查询流程不一样的是，更新流程还涉及两个重用的日志模块，redo log(重做日志) 和 binlog(归档日志)。
        
    2、重要的日志模块：redo log
    
        《孔乙己》文章中，酒店掌柜有一个粉板，专门用来记录客人的赊账记录，如果赊账的人不多，
        就把客户名和账目写在板上，如果赊账人太多，粉板记不下的时候，掌柜还需要一个专门记录
        赊账的账本。
        
        如果有人要赊账或者还账的话，掌柜的一般有两种做法:
            一种做法是把账本翻出来，把这次赊账加上去或者扣除掉。
            另一种做法是现在粉板上记录这次的账，等打烊以后再把账本翻出来核算。
            
        同样，在MySQL 里面也有这个问题，如果每次更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，
        然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题， MySQL 的设计者就用类似酒店粉板
        的思路来提升更新效率。
        
        粉板和账本配合的整个过程，其实就是 MySQL 里面经常说的 WAL 技术， WAL 的全称是 Write-Ahead Logging
        它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。
        
        具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log (粉板)里面，并更新内存，
        这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往
        是在系统比较空闲的时候做。
        
        如果今天赊账不多，掌柜可以等打烊后再整理，但如果某天赊账特别多，粉板写满了，这时候，掌柜只好放下手中
        的活，把粉板中的一部分赊账记录更新到账本中，然后，把这些记录从粉板上擦掉，为记新账腾出新空间。
        
        与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么
        这块“粉板”总共可以记录 4GB 操作。
        
        有了 redo log, InnoDB 就可以保证即使数据库发送异常重启，之前提交的记录都不会丢失，这个能力成为 crash-safe。
        要理解 crash-safe 这个概念，可以想想赊账记录的例子，只有赊账记录在粉板上或写在账本上，这后即使掌柜的忘记了
        突然停业几天，恢复生意后可以通过账本和粉板上的数据明确赊账账目。
        
        
    3、 重要的日志模块：binlog:
    
        MySQL 有两块：一块是 Server 层有自己的日志，称为 binlog (归档日志)   
        上面的聊到的粉板 redo log 是 InnoDB 引擎特有的日志。
        
        两种日志 redo log 和 binlog 有以下三点不同：
        
            a. redo log 是 InnoDB 引擎特有的; binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
            
            b. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；
               binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1”。
               
            c. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。
                “追加写” 是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
                
    4、执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：
    
        a.  执行器先找到引擎取 ID = 2 这一行。 ID 是主键，引擎直接用树搜索找到这一行。
            如果 ID = 2 这一行所在的数据页本来就走内存内，就直接返回给执行器；否则
            需要先从磁盘读入内存，然后再返回。
            
        b.  执行器拿到引擎给的行数据，把这个值加上 1， 比如原来是 N, 现在就是 N+1,
            得到新的一行数据，再调用引擎接口写入这行新数据。
            
        c.  引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，
            此时 redo log 处于 prepare 状态，然后告知执行器执行完成了，随时可以提交事务。
            
        d.  执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
        
        e.  执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。
                  
                    
    5、两阶段提交：
    
        那可能注意到了，redo log 的写入拆成了两个步骤：prepare 和 commit,这就是“两阶段提交”
        为什么必须要有“两个阶段提交”呢，是为了让两份日志之间的逻辑一致。
        
        怎么让数据库恢复到半月内任意一秒的状态？
        我们前面说了，binlog 会记录所有的逻辑操作，并且采用“追加写” 的形式，如果 DBA 承诺半个月内
        可以恢复，那么备份系统中一定会保存最近半月的所有 binlog，同时系统会定期做正库备份。
        
        当需要恢复到指定的某个时间某一秒时，比如某条下午两点发信中午12点有一次误删表，需要找回数据
        那么需要这么做：
        
            首先，从备份恢复到临时库。
            
            然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。
            
    6、小结：
    
        今天，介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。
        
        redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数
        设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。
        
        sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。
        
        
"""03| 事务隔离：为什么你改了我还看不见？"""

    
    简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，
    事务支持是在引擎层实现的。
    
    1、隔离性和隔离级别：
    
        提到事务，你肯定想到 ACID(Atomicity、Consistency、Isolation、Durability,
        即原子性、一致性、隔离性、持久性)，今天说说“隔离性”。
        
        原子性: 指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.
        一致性：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变. 
        隔离性：指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致. 
        持久性：指事务运行成功以后,就系统的更新是永久的.不会无缘无故的回滚.
        
        当数据库上有多个事务同时执行的时候，就可能出现
            脏读(dirty read)、
            不可重复读(non-repeatable read)
            幻读(phantom read)的问题，为了解决这些问题，就有了“隔离级别”的概念。
            
            脏读：是指在一个事务处理过程里读取了另一个未提交的事务中的数据。
            
            不可重复读：是指在一个事务里，多次读同一数据。在这个事务还没有结束时，另一个事务也访问该
                        同一数据。那么，在第一个事务中的两次读取数据之间，由于第二个事务的修改，那么
                        第一个事务两次读到的数据可能不一样的。这样就发生了在一个事务内两次的数据是不
                        一样的，因此称为不可重复读。    
            
            幻读：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，
                  这种修改涉及到表中的全部数据行。同时，第二个事务也修改了这个表中的数据，这种修改
                  是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改
                  的数据行，就好像发生了幻觉一样。
            
            
        隔离的越严实，效率就会越低。我们需要在二者之间寻找一个平衡点。
        SQL 标准的事务隔离级别包括：
            读未提交(read uncommitted)、
            读提交(read committed)、
            可重复读(repeatable read)、
            串行化(serializable)。
        
        读未提交是指：一个事务还没有提交时，它做的变更就能被别的事务看到。
        
        读提交是指：一个事务提交之后，它做的变更才会被其他事务看到。
        
        可重复读是指：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。
                    当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
        
        串行化：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。
               当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
               
                        
                     
        隔离级别        脏读（Dirty Read）     不可重复读（NonRepeatable Read）    幻读（Phantom Read）
        
        未提交读        可能                       可能                       可能

        已提交读        不可能                     可能                       可能

        可重复读        不可能                     不可能                     可能

        可串行化        不可能                     不可能                     不可能       
        
            
    2、 我们用一个例子说明几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，
        下面按照时间顺序执行两个事务的行为。
        
        mysql> create table T(c int) engine = InnoDB;
        insert into T(c) values (1);
        
        事务A:                            事务B:
        
        启动事务查询得到值 1               启动事务
        
                                         查询得到值 1 将 1 改成 2
                                           
        查询得到值 V1
        
                                         提交事务 B
                                         
        查询得到值 V2
        
        提交事务 A
        
        查询得到值 V3
        
        若隔离级别是“读未提交”，则 V1 的值就是 2。这个时候虽然还没有提交，但是结果已经被 A 看到了，
        因此，V2 和 V3 的值也都是 2。
        
        若隔离级别是“读提交”，则 V1 的值是 1，V2 的值是 2 。事务 B 的更新在提交后才能被 A 看到。
        所以，V3 的值也是 2。
        
        若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：
        事务在执行期间看到的数据前后必须是一致的。
        
        若隔离级别是“串行化”，则在事务 B 执行 “将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，
        事务 B 才可以继续执行，所以 A 的角度看，V1、V2 的值是 1， V3 的值是 2。
        
        
        在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。
        在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
        在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。
        在“读未提交”隔离级别下直接返回记录上的最新值，没有视图的概念。
        在“串行化”隔离级别下直接用加锁的方式来避免并行访问。
        
    3、配置方式：
    
        Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Orcal 迁移到 MySQL 的应用，
        为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”
        
        SELECT @@tx_isolation;  查看当前事务的隔离级别
        set session transaction isolation level read uncommitted; 设置事务的隔离级别
                
        mysql> SELECT @@tx_isolation;
        +-----------------+
        | @@tx_isolation  |
        +-----------------+
        | REPEATABLE-READ |
        +-----------------+
        1 row in set (0.02 sec)
        
        mysql> set session transaction isolation level read uncommitted;
        Query OK, 0 rows affected (0.02 sec)
        
        mysql> SELECT @@tx_isolation;
        +------------------+
        | @@tx_isolation   |
        +------------------+
        | READ-UNCOMMITTED |
        +------------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level read committed
            -> ;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                                
        +----------------+
        | @@tx_isolation |
        +----------------+
        | READ-COMMITTED |
        +----------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level repeatable read;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                                  
        +-----------------+
        | @@tx_isolation  |
        +-----------------+
        | REPEATABLE-READ |
        +-----------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level serializable;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                               
        +----------------+
        | @@tx_isolation |
        +----------------+
        | SERIALIZABLE   |
        +----------------+
        1 row in set (0.00 sec)
        
        
        总结来说，存在即合理，那个隔离级别都在自己的应用场景。
        “可重复读”隔离级别就很方便，事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
        
    4、事务隔离实现：
    
        在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。
        记录上的最新值，通过回滚操作，都可以得到前一个状态的值。                                                      
        当没有事务用的回滚日志时，回滚日志会被删除。
        
        基于上面情况，不建议使用长事务，长事务意味着系统里面会存在很老的事务视图。
        由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库
        里面它可能用到回滚记录都必须保留，导致大量占用存储空间。
        
    5、事务的启动方式：
        
        MySQL 的事务启动的几种方式：
        
        a、显式启动事务语句，begin 或 start transaction。配套的提交语句是 commit，回滚语句 rollback。
            
        b、set autocommit = 0, 这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句
            这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句
            或者断开连接。
            
        c、有些客户端连接默认链接成功后先执行set autocommit = 0 的命令，这就导致了接下来的查询都在事务中，
            如果是长连接，就导致了意味的长事务。
            
        建议使用： set autocommit = 1, 通过显式语句的方式启动事务。
        
        你可以在 infomation_schema 库的 innodeb_trx 这个表中查询长事务，比如下面语句，查找超过60s 的事务：
        
        select *from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;            
        
        mysql> select *from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60; 
        ERROR 1227 (42000): Access denied; you need (at least one of) the PROCESS privilege(s) for this operation
        mysql> 
        mysql> 
        mysql> desc information_schema.innodb_trx; 
        +----------------------------+---------------------+------+-----+---------------------+-------+
        | Field                      | Type                | Null | Key | Default             | Extra |
        +----------------------------+---------------------+------+-----+---------------------+-------+
        | trx_id                     | varchar(18)         | NO   |     |                     |       |
        | trx_state                  | varchar(13)         | NO   |     |                     |       |
        | trx_started                | datetime            | NO   |     | 0000-00-00 00:00:00 |       |
        | trx_requested_lock_id      | varchar(81)         | YES  |     | NULL                |       |
        | trx_wait_started           | datetime            | YES  |     | NULL                |       |
        | trx_weight                 | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_mysql_thread_id        | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_query                  | varchar(1024)       | YES  |     | NULL                |       |
        | trx_operation_state        | varchar(64)         | YES  |     | NULL                |       |
        | trx_tables_in_use          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_tables_locked          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_lock_structs           | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_lock_memory_bytes      | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_rows_locked            | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_rows_modified          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_concurrency_tickets    | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_isolation_level        | varchar(16)         | NO   |     |                     |       |
        | trx_unique_checks          | int(1)              | NO   |     | 0                   |       |
        | trx_foreign_key_checks     | int(1)              | NO   |     | 0                   |       |
        | trx_last_foreign_key_error | varchar(256)        | YES  |     | NULL                |       |
        | trx_adaptive_hash_latched  | int(1)              | NO   |     | 0                   |       |
        | trx_adaptive_hash_timeout  | bigint(21) unsigned | NO   |     | 0                   |       |
        +----------------------------+---------------------+------+-----+---------------------+-------+
        22 rows in set (0.05 sec)

"""04| 深入浅出索引 (上)"""
    
    简单来说：索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。
  
    1、索引的常见模型
    
        索引的出现时为了提高查询效率，但是实现索引的方式却有很多中，索引就引入了索引模型的概念。
        最常见的三种：哈希表、有序数组、搜索树
        
        哈希表：
            
            哈希表是一种以 键-值(key-value)存储数据的结构，
            所以哈希表这种结构适用于只有等值查询的场景。
            比如 Memcached 及其他一些 NoSQL 引擎。
        
        有序数组：
            
            有序数组在等值查询和范围查询场景中的性能都有非常优秀。
            里面是存储的数据是顺序排序的，用二分法进行查找，时间复杂度 O(log(N))。
            如果仅仅看查询效率，有序数组就是最好的数据结构，但是，在需要更新数据的
            时候就非常麻烦了，你往中间插入一个记录就必须的挪动后面的所有记录，成本太高。
            所以，有序数组索引只适用于静态存储引擎，里面的数据不会修改。
        
        二叉树：   
            
            二叉搜索树特点：左节点小于父节点， 父节点小于右节点。
            二叉搜索树的时间复杂度是 O(logN), 更新复杂度也是 O(logN)。
            
            二叉树是搜索效率最高的，但是实际上大多数数据库存储并不使用二叉树，
            其原因，搜索不止存在内存中，还有写到磁盘上。
            
            你可以想象一下一颗 100 万节点的平衡二叉树，树高 20，一次访问需要访问 20 个数据块。
            单独访问一行可能需要 20 个 10 ms 的时间。查询很慢。
            
            为了让一个查询尽量少第读磁盘，必须让查询过程尽量少的数据块。那么
            我们不应该使用 二叉树，而是应该使用 "N 叉"树。这里“N叉”树的 N 取决于数据块大小。
            
            N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用到数据库引擎中。
            
            
    2、MySQL 中，存储引擎的实现，InnoDB的索引模型：           
        
        在 MySQL 中，索引是在存储引擎层实现的，所以没有统一的标准，不同的存储引擎索引的工作方式并不一样。
        
        在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。
        InnoDB 使用了 B+ 树索引模式，所以数据都是存储在 B+ 树中的。
        
        每一个索引在 InnoDB 里面对应一颗 B+ 树。
        
        假设，我们有一个主键列为 ID 的表，表中有字段 k, 并且在 k 上有索引。
        
        这个表的建表语句是：
        
            mysql> create table T(
            id int primary key,
            k int not null,
            name varchar(16),
            index(k))engine=InnoDB;    
        
        索引类型分为主键索引和非主键索引。
        
        主键索引的叶子节点存的是正行数据。在 InnoDB 里，主键索引也被称为聚簇索引(clustered index)。
        非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引页被称为二级索引(secondary index)。
        
        基于主键索引和普通索引的查询有什么区别？
            
            a. 如果语句是 select *from T where ID=500,即主键查询方式，则只需要搜索 ID 这颗 B+ 树。
            
            b. 如果语句是 select *from T where k = 5,即普通索引查询方式，则需要先搜索 k 索引树，得到
                ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。
                
        也就是说，基于非主键索引的查询需要多扫描一次索引树，因此，应尽量使用主键查询。
        
    3、索引维护：
    
        B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。
        
        你可能在一些建表规范里面见过类似的描述，要求建表的语句里一定要有自增主键。
        当然，事务绝对，我们分析一下，那些场景需要使用自增主键，而那些场景不应该。
                    
        自增主键是指自增序列上定义的主键，在建表语句中一般是这么定义的：NOT NULL PRIMARY KEY AUTO_INCREMENT.
        插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 的最大值加 1 作为下一条记录的 ID 值。
        
        也就是说，自增主键的插入数据模式，正符合递增插入模式的场景。每次插入一条新的记录。
        都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
        而又业务逻辑的字段做主键，则往往不容易保证有序插入，这些写数据成本性对较高。
        
        显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用空间也就越小。
        所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。
        
        有没有什么场景适合用业务字段直接做主键的呢？
        还是有的，比如，有些业务的场景需求是这样的：
            a. 只有一个索引。
            b. 该索引必须是唯一索引。
        
        你一定看的出来，就是典型的 KV 场景。
        由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。
        这时候要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，
        可以避免每次查询需要搜索两颗树。
            
                       
"""05| 深入浅出索引 (下)"""

    在下面的表 T 中，如果我执行 select *from T where k between 3 and 5;
    需要执行几次树的搜索操作，会扫描多少行？
    
    mysql > create table T(
    ID int primary key,
    k int NOT NULL DEFAULT 0,
    s varchar(16) NOT NULL DEFAULT '',
    index k(k))engine=InnoDB;
    
    insert into T values(100,1,'aa'),(200,2,'bb'),(300,3,'cc'), (400,4,'dd'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');         
        
    现在我们看这条 SQL 查询语句的执行流程：
    
        a. 在 k 索引树上找到 k = 3 的记录，取得 ID = 300;
        b. 再到 ID 搜索树查找到 ID=300 对应的 R3;
        c. 在 k 索引树取下 k = 5，取得 ID = 500;
        d. 再回到 ID 索引树查到 ID=500 对应的 R4;
        e. 在 k 索引树下取下一个值 k = 6,不满足条件，循环结束。
        
    在这个过程中，回到主键索引树搜索的过程，我们成为回表。
    可以看到，这个查询过程读了 k 索引树的 3 条记录（a, c和 e）,回表了两次（2 和 4）。
    在这个例子中，由于查询结果所需的数据只有在主键索引上有，所以不得不回表。
    那么，有没有可能经过索引优化，避免回表过程呢？
      
    1、覆盖索引：
    
        如果执行的语句是 select ID from T where k betweent 3 and 5;
        这时只需要查 ID 的值，而 ID 的值已经在 K 索引树上了。也就是说，
        在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖查询。
        
        由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引
        是一个常用的性能优化手段。
        
        需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，
        R3~R5(对应的索引 k 上的记录项)，但是对于 Server层来说，它就是
        找到引擎拿到了两条记录，因此，MySQL 认为扫描行数是 2。
        
    2、最左前缀原则：
    
       如果所有字段都建立索引是不是太多了，单独为一个不常用的字段增加索引，感觉太浪费。这种应该怎么做？
            
       B+ 树这种索引结构，可以利用索引的 “最左前缀”，来定位记录。
       
       不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。
       这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。
       
       基于上面的最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。
       这里我们的评估标准是，索引的复用能力，因为可以支持最左前缀，索引当已经有了（a,b）这个联合索引后，
       一般不需要在单独在 a 上建立索引了。
       因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
       
    3、索引下推：
    
        最左前缀可以用于在索引中定位记录。这时，那些不符合最左前缀的部分，会怎么样呢？
        
        例如下面的 SQL 语句：
            
            mysql > select * from tuser where name like '张 %' and age = 10 and ismale = 1;
             
        你已经知道了前缀索引的规则，所以这个语句在搜索树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。
        当然，这总比全表扫描要好。
        
        在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。
        而 MySQL 5.6 后引入了索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，
        直接过滤掉不满足条件的记录，减少回表次数。
        
        例如下面的一个表中数据：
        
            name     age   ID   ismale
            张六      30    ID3   ..
            张三      10    ID4   ..
            张三      10    ID5   ..
            张三      20    ID6   ..
            
        如果索引里只有(name)，这个过程 InnDB 并不会去看 age 的值，只是按顺序把 “name” 第一个字“张”的
        记录一条条取出来回表，因此，需要回表 4 次。
        
        InnoDB(name, age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断跳过。则只需要回表两次。
        
    4、小结：
    
        在满足语句需求的情况下，尽量少地访问资源是数据库设计在重要原则之一。
        尤其是在设计表的结构时，也要减少资源消耗作为目标。
        
        
"""06| 全局锁和表锁：给表加个字段怎么有这么多阻碍？"""                    
        
    数据库锁设计的初衷是处理并发问题，作为多用户共享的资源，当出现并发访问的时候，
    数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重用数据结构。
    
    根据加锁的范围，MySQL 里面的锁大致可以分成 全局锁、表级锁和行锁三类。
    
    1、全局锁:
        
        全局锁就是对数据库实例加锁。
        MySQL 提供了一个加全局读锁的方法，命令是：
        Flush tables with read lock(FTWRL)。
        当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的一下语句会被阻塞：
        数据更新语句（数据增删改）、数据定义语句(建表、修改表结构)和更新类事务的提交语句。
        
        全局锁的典型使用场景是，做全库逻辑备份。
        也就是把整个库每个表都 select 出来存成文本。
        
        但是让整个库上备份，听上去就很危险：
            a. 如果你从主库上备份，那么备份期间都不能执行更新，业务基本上就得停摆。
            
            b. 如果你从库上备份，那么备份期间从库不能执行主库同步过来的 binlog,会导致主从延迟。
            
    2、表级锁：
    
        MySQL 里面表级锁有两种：一种是表锁，一种是元数据锁(meta data lock, MDL)。
        
        表锁的语法是 lock tables ... read/write。
        与 FTWRL 类似，可以用  unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。
        需要注意的，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
        
        举个例子，如果某个线程 A 执行下面语句：
        
            lock tables t1 read, t2 write;
            
            这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。
            同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1,读写 t2 操作。
    
    3、MDL 表锁：
            
        MDL: MDL 不需要显示使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。
        在MySQL 5.5 版本中引入了 MDL, 当对一个表做增删改查的操作时候，加 MDL 读锁；
        当对表结构变更操作的时候，加 MDL 写锁。
        
        读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
        读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。
        因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。
        
        给一个表加字段、或者修改字段或者加索引，需要扫描全表数据。操作不慎就会出问题。
        我们看一下下面的操作序列,表t：
            
            session A           session B        session C       session D
            
              begin;
              select *
              from t limit 1;
        
                                selsect *
                                from t limit 1;                    
        
                                                  alter table t
                                                  add f int;
                                                  (blocked) 
                                                                   
                                                                   select *
                                                                   from t limit 1
                                                                   (blocked)
                                                                   
        session A 先启动，对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。
        之后，session C 会被 blocked,因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，
        因此，只能被阻塞。
        
        如果只有 session C 自己被阻塞没有什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 
        session C 阻塞。所有的对表增删改查操作都需要先申请 MDL 读锁，都被锁住，等于这个表完全不可以读写了。
        
        如果这个表有很频繁查询语句，这个库的线程很快会爆满。事务中的 MDL 锁，在语句执行时申请，但是语句结束
        之后不会马上释放，而是等到事务提交后再释放。
        
    4、如何安全的给表加字段：    
        
       a. 首先解决长事务，事务不提交，就会一直占着 MDL 锁。 kill 掉长事务。
       
       b. 如果表的访问量很大，kill 未必管用，比较理想的机制是，在 alter table 语句里面设定等待时间，
          如果在指定时间内拿到 MDL 写锁最好，拿不到也不要阻塞后面业务语句，先放弃，再重试命令重复这个过程。
          
       MariaDB 已经合并了 AliSQL 的这个功能，所有两个开源项目都支持 DDL NOWAIT/WAIT n 这个语法：
       
        ALTER TABLE tbl_name NOWAIT add column ...
        ALTER TABLE tbl_name WAIT N add column ...
    
    5、小结：    
       
       全局锁主要用在逻辑备份过程中。
       表锁一般都在数据库引擎不支持行锁的时候才会被用到。
       
       如果你发现程序里有 lock tables 这样的语句，可能情况是：
        a. 系统使用的是 MyISAM 这类不支持事务的引擎。
        
        b. 引擎升级了，代码还没有升级。
                
                 
"""07| 行锁功过：怎样减少行锁对性能的影响"""

    MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，
    比如：MySAM 引擎就不支持行锁，不支持行锁意味着并发控制只能使用表锁，对于
    这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就影响到业务的并发度。
    InnoDB 支持行锁，这也是 MyISAM 被 InnoDB 代替的原因。
    
    行锁就是针对数据表中行记录的锁。比如事务 A 更新一行，为这时候事务 B 也要更新一行，
    则必须等事务 A 的操作完成之后才能进行更新。
    
    1、从两个阶段的锁说起：
    
        假设字段 id 是表 t 的主键：
        
        事务 A                               事务 B
        
        begin;
        update t set k=k+1 where id=1;
        update t set k=k+1 where id=2;
        
                                             begin;
                                             update t set k=k+2 where id=1;
                                             
        commit;
        
        上面的 事务B 的 update 语句会被阻塞，直到 事务A执行comit之后，事务B 才能继续执行。
        在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到
        事务结束时才释放。这就是两个阶段锁协议。
        
        根据上面的设定，如果你的事务需要锁多个行，要把最可能造成锁冲突，最可能影响并发读的锁
        尽量往后放。
        
    2、死锁和死锁检测：
        
        当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致
        这几个线程都进入无限等待的状态，称为死锁。
        
        事务 A                              事务 B
        
        begin;
        update t set k=k+1 where id=1;      begin;
                           
                                            update t set k=k+1 where id=2;
                                            
        update t set k=k+1 where id=2;
        
                                            update t set k=k+1 where id=1;
                                                                                
        事务 A 在等待事务 B 释放 id = 2 的行锁，而事务 B 在等待事务 A 释放 id = 1的行锁。
        事务A 和事务B 在互相等待对方的资源释放，就进入死锁状态。当出现死锁后有两种策略：
            一种策略，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
            另一种策略，发起死锁检测，发现死锁后，主要回滚死锁链条中的某一个事务，让其他事务得以继续执行。
            将参数 innodb_deadlock_detect 设置为 on,表示开启这个逻辑。
            
    3、怎样解决热点行更新导致性能问题？
    
        每个新来的被堵住的线程，都有判断会不会由于自己的加入导致了死锁，这个时间复杂度是 O(n)操作。
        假设有 1000 个并发线程同时更新同一行，那么死锁检测操作就是 100万这个量级。虽然最终检测
        的结构是没有死锁，但是期间会消耗大量的 CPU 资源。因此，你会发现 CPU 利用率很高，但是每秒
        执行不了几个事务。
        
        一种办法是头痛医头，就是如果你能确保这个业务一定不会出现死锁，可以临时把这个死锁检测关掉。
        另一种思路是控制并发度。
        
    4、小结：
    
        开发时候如何正确安排事务语句：原则是如果事务中需要锁多个行，要把尽可能造成锁冲突、最可能
        影响并发度的锁的申请时机尽量往后放。
        
        但是，调整顺序并不能完全避免死锁，减少死锁的主要方向是控制访问相同资源的并发事务量。
        
        
"""08| 事务到底是隔离的还是不隔离的？"""        
    
    1、在 MySQL 里，有两个“视图”的概念：
        
        一个是 view, 它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。
        创建视图的语法是 create view ..., 而它的查询方法与表一样。
        
        另一种是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view, 用于
        支持 RC(Read Committed, 读提交) 和 RR(Repeatable Read, 可重复读)隔离级别的实现。
        
        它没有物理结构，作用是事务执行期间用来定义“我们看到什么数据”
        
    2、“快照”在 MVCC 里是怎么工作的？    
        
        在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整个库的。
        这个快照是怎么实现的？
        
        InnoDB 里面每个事务有一个唯一的事务 ID,叫做 transaction id。 它是在事务开始的时候
        向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。
        
        而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并把
         transaction id 赋值给这个数据版本的事务ID,记为 row trx_id。同时，旧的数据版本要保留，
         并且在新的数据版本中，能够有信息可以直接拿到它。
         
         也就是说，数据表中的一行记录，其实可能有多个版本(row),每个版本有自己的 row trx_id。
                     
         按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果，但是之后，
         这个事务执行期间，其他事务的更新对它不可见。
         
         事实上， InnoDB 为每个事务构成了一个数组，用来保存这个事务启动瞬间，当前正在活跃
         的所有事务 ID。活跃指的是，启动了但还没提交。
        
         InnoDB 利用了 “所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。
         
    3、更新逻辑：
    
        更新数据都是先读后写的，而这个读，只能读当前值，称为“当前读”（current read）。
        
        事务的可重复读的能力是怎么实现的？
        可重复读的核心就是一致性读(consistent read);而事务更新数据的时候，只能用当前读。
        如果当前的记录的行被其他事务占用的话，就需要进入锁等待。
        
        而读提交的逻辑和可重复读的逻辑类似，主要区别是：
            
            在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都
            共用这个一致性视图；
            在读提交隔离级别下，每一个语句执行前都会重新计算出一个新的视图。
            
    4、小结：
    
        InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的
        一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据
        版本的可见性。
        
        对于可重复读，查询只承认在事务启动之前就已经提交完成的数据；
        对于读提交，查询只承认在语句启动前就已经提交完成的数据。
        
        而当前读，总是读取已经提交完成的最新版本。
        
        
"""09| 普通索引和唯一索引，应该怎么选择？"""                 
            
                    
    我们从两种索引对查询语句和更新语句的性能影响来进行分析：
    
    1、查询过程：
    
        在 InnoDB 的数据时按数据页为单位来读写的，也就是说，当需要读一条记录的时候，
        并不是讲这个记录本身从磁盘读出来，而是以页为单位，将整体读入内存。在 innoDB中，
        每个数据页的大小默认是16KB。
        
        查询语句 ：select id from T where k=5;
       
        对于普通索引来说，查找满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个
        不满足 k=5 条件的记录。
        
        对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
        
        由于数据库是按数据页为单位进行读写的，索引普通索引和唯一索引区别微乎其微。
        
    2、更新过程：
    
        change  buffer:
            
            当需要更新一个数据页的时候，如果数据页在内存中就直接更新，如果这个数据页在内存
            中不存在，在不行影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，
            这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入
            内存，然后执行 change buffer 中与这个页有关的操作，通过这种方式保证数据逻辑的正确性。
            
            将change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。
            显然，如果将更新操作先记录 change buffer，减少读磁盘，语句执行速度明显提升。
            
            change buffer 只用于普通索引。
            
        对于更新操作有两种情况：例如在表中插入一个新记录(4,400)的话，InnoDB如何操作
        
            第一种情况，这个记录要更新的目标也在内存中存在：
            对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束。
            对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
            两种索引，只是差别一个判断，只会消耗微小的 CPU 时间。
            
            第二种情况，这个记录要更新的目标页不在内存中。
            对于唯一索引来说，需要将数据页读入内存，判断到么有冲突，插入这个值，语句执行结束。
            对于普通索引，则更新记录在 change buffer，语句执行结束。
            普通索引性能更高。
            
    3、change buffer 的使用场景：
    
        change buffer 对于更新过程的加速作用，change buffer 只限于用在普通索引的场景下，
        而不使用与唯一索引。
        
        因为 merge 的时候是真正进行数据更新的时候，而change buffer 的主要目的就是讲记录的
        变更动作缓存下来，所以在一个数据页做 merge之前，change buffer 记录的变更越多，收益越大。
        
        因此，对于写多读少的业务来说，页面的写完以后马上访问的概率比较小，此时change buffer的使用
        效果最好。这种业务是账单类、日志类系统。
        
        反过来，如果有业务更新之后，马上查询，会立刻出发 merge ,change buffer 反而起到反作用。
        
    4、索引的选择和实践：
    
        普通索引和唯一索引在查询上没有差别，主要考虑是对更新性能影响。
        
        redo log 和 change buffer:
        
            redo log 主要节省的是随机写磁盘的 IO 消耗。
            change buff 主要节省则是随机读磁盘的 IO 消耗。
                        
                        
"""10| MySQL 为什么有时候会选错索引"""            
            
           
         
         
         
         
         
        
        
        
        
        
        
        
        
        
        
        
        
                    
                   
        
        
            
            
        
               
        
            
    
        
        
















    