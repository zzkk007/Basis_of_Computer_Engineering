"--------------------------------------------------------"

           极客时间 林晓斌 《MySQL 实战 45 讲》

"--------------------------------------------------------"

"""01| 基础架构: 一条 SQL 查询语句是如何执行的？"""

    1、MySQL 组成:
    
        MySQL 可以分为 Server 层和存储引擎层两部分。
        
        Server 层包括：连接器、查询缓存(MySQL 8.0删除缓存模块)、分析器、优化器、执行器等。
        涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)
        所有跨存储引擎的功能都在这一层实现，比如：存储过程、触发器、视图等。
        
        存储引擎：负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等
        多个存储引擎。MySQL 5.5 默认 InnoDB 存储引擎。    
        不同的存储引擎共用一个 Server 层。也就是从连接器到执行器的部分。
        
    2、连接器:
        
        连接器负责跟客户端建立连接、获取权限、维持和管理连接。
        连接命令一般是这么写：
            
            mysql -h$ip -P$port -u$user -p
            
        数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。
        短连接则是指每次执行完很少的几次查询就断开连接，下一次查询再重新建立一个。
        
        建立连接的过程比较复杂，尽量减少建立连接的动作，也就是尽量使用长连接。
        但是，全部使用长连接，MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程
        中临时使用的内存是管理在连接对象里面的，这些资源会在断开连接的时候才释放。
        如果长连接积累下来，可能导致内存占用太大，被系统强行杀掉（OOM）,从现象
        上看就是 MySQL 异常重启。
        
        解决办法：
        
            a. 定期断开长连接。
            
            b. 如果你使用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过
                执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新
                做权限验证，但是会恢复到刚刚建完时的状态。
                
    3、查询缓存：
    
        MySQL 拿到一个请求后，会先到查询缓存看看，之前是不是执行过这条语句，之前执行过的语句及结果
        可能会以 key-value 对的形式被直接缓存到内存中。key 是查询的语句。value是查询的结果。
        如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结构会被存入查询缓存中。
        
        但是建议不要使用缓存，往往弊大于利。
        MySQL 将参数 query_cache_type 设置成 DEMAND, 这样对于默认的 SQL 语句都不使用查询缓存。
        
        MySQL8.0 版本直接将查询缓存整块功能删掉了。
        
    4、分析器：
    
        分析器 先会做“词法分析”。你输入的由多个字符串和空格组成的一条 SQL 语句， MySQL 需要识别
        出里面的字符串分别是什么，代表什么。
        
        然后是“语法分析”。根据“词法分析”结果，语法分析会根据语法分析规则，判断是否满足 MySQL 语法。
        
    5、优化器：
    
        经过 分析器，MySQL 就知道你要做什么了，在开始执行之前，还要经过优化器的处理。
        
        优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多个关联(join)
        的时候，决定各个表的连接顺序。
        
        mysql > select * from t1 join t2 using(ID) where t1.c = 10 and t2.d = 20;
        
        即可以先从表 t1 里面取出 c = 10 的记录的 ID 值，再根据 ID 值关联到表 t2, 再判断 t2 里面 d 的值是否等于 20.        
        也可以先从表 t2 里面取出 d = 20 的记录的 ID 值，再根据 ID 值关联到表 t1, 再判断 t1 里面 c 的值是否等于 10.

        优化器阶段完成后，这个语句的执行方案就确定下来了。然后进行执行器阶段。                     
            
    6. 执行器：
    
        mysql> select *from T where ID = 10;
        
        开始执行的时候，要判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。
        如果有权限，就开打表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。
        
        比如上面的例子表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：
        
            a. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，
                如果是则将这行存在的结果集中;
                
            b. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
            
            c. 执行器将上述遍历过程中所有满足条件的行组成记录集作为结果集返回给客户端。
            
        至此，这个语句就执行完成了。
        
        对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，
        之后循环取“满足条件的下一行”这个接口，这些接口都是在引擎中定义好的。
        
        你会在数据库慢日志看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。
        这个值就是在执行器每次调用引擎获取数据行的时候累加的。
        
        
"""02| 日志系统： 一条 SQL 更新语句是如何执行的"""        

    1、一条更新语句的执行流程是怎么样的呢？
        
        表的创建语句，这个表有一个主键 ID 和一个整型字段 c:
            mysql> create table T(ID int primary key, c int);
        
        如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：
            mysql> update T set c = c+1 where ID=2;
    
        更新语句的执行流程和查询流程一样，都有经过 连接器、清除缓存(语句会把表T上所有的缓存结果都清空)，
        分析器、执行器。                    
        与查询流程不一样的是，更新流程还涉及两个重用的日志模块，redo log(重做日志) 和 binlog(归档日志)。
        
    2、重要的日志模块：redo log
    
        《孔乙己》文章中，酒店掌柜有一个粉板，专门用来记录客人的赊账记录，如果赊账的人不多，
        就把客户名和账目写在板上，如果赊账人太多，粉板记不下的时候，掌柜还需要一个专门记录
        赊账的账本。
        
        如果有人要赊账或者还账的话，掌柜的一般有两种做法:
            一种做法是把账本翻出来，把这次赊账加上去或者扣除掉。
            另一种做法是现在粉板上记录这次的账，等打烊以后再把账本翻出来核算。
            
        同样，在MySQL 里面也有这个问题，如果每次更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，
        然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题， MySQL 的设计者就用类似酒店粉板
        的思路来提升更新效率。
        
        粉板和账本配合的整个过程，其实就是 MySQL 里面经常说的 WAL 技术， WAL 的全称是 Write-Ahead Logging
        它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。
        
        具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log (粉板)里面，并更新内存，
        这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往
        是在系统比较空闲的时候做。
        
        如果今天赊账不多，掌柜可以等打烊后再整理，但如果某天赊账特别多，粉板写满了，这时候，掌柜只好放下手中
        的活，把粉板中的一部分赊账记录更新到账本中，然后，把这些记录从粉板上擦掉，为记新账腾出新空间。
        
        与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么
        这块“粉板”总共可以记录 4GB 操作。
        
        有了 redo log, InnoDB 就可以保证即使数据库发送异常重启，之前提交的记录都不会丢失，这个能力成为 crash-safe。
        要理解 crash-safe 这个概念，可以想想赊账记录的例子，只有赊账记录在粉板上或写在账本上，这后即使掌柜的忘记了
        突然停业几天，恢复生意后可以通过账本和粉板上的数据明确赊账账目。
        
        
    3、 重要的日志模块：binlog:
    
        MySQL 有两块：一块是 Server 层有自己的日志，称为 binlog (归档日志)   
        上面的聊到的粉板 redo log 是 InnoDB 引擎特有的日志。
        
        两种日志 redo log 和 binlog 有以下三点不同：
        
            a. redo log 是 InnoDB 引擎特有的; binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
            
            b. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；
               binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1”。
               
            c. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。
                “追加写” 是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
                
    4、执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：
    
        a.  执行器先找到引擎取 ID = 2 这一行。 ID 是主键，引擎直接用树搜索找到这一行。
            如果 ID = 2 这一行所在的数据页本来就走内存内，就直接返回给执行器；否则
            需要先从磁盘读入内存，然后再返回。
            
        b.  执行器拿到引擎给的行数据，把这个值加上 1， 比如原来是 N, 现在就是 N+1,
            得到新的一行数据，再调用引擎接口写入这行新数据。
            
        c.  引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，
            此时 redo log 处于 prepare 状态，然后告知执行器执行完成了，随时可以提交事务。
            
        d.  执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
        
        e.  执行器调用引擎的提交事务接口，引擎把刚刚写入的 red log 改成提交（commit）状态，更新完成。
                  
                    
    5、两阶段提交：
    
        那可能注意到了，redo log 的写入拆成了两个步骤：prepare 和 commit,这就是“两阶段提交”
        为什么必须要有“两个阶段提交”呢，是为了让两份日志之间的逻辑一致。
        
        怎么让数据库恢复到半月内任意一秒的状态？
        我们前面说了，binlog 会记录所有的逻辑操作，并且采用“追加写” 的形式，如果 DBA 承诺半个月内
        可以恢复，那么备份系统中一定会保存最近半月的所有 binlog，同时系统会定期做正库备份。
        
        当需要恢复到指定的某个时间某一秒时，比如某条下午两点发信中午12点有一次误删表，需要找回数据
        那么需要这么做：
        
            首先，，从备份恢复到临时库。
            
            然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。
            
    6、小结：
    
        今天，介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。
        
        redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数
        设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。
        
        sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。
        
        
"""03| 事务隔离：为什么你改了我还看不见？"""

    
    简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，
    事务支持是在引擎层实现的。
    
    1、隔离性和隔离级别：
    
        提到事务，你肯定想到 ACID(Atomicity、Consistency、Isolation、Durability,
        即原子性、一致性、隔离性、持久性)，今天说说“隔离性”。
        
        原子性: 指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.
        一致性：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变. 
        隔离性：指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致. 
        持久性：指事务运行成功以后,就系统的更新是永久的.不会无缘无故的回滚.
        
        当数据库上有多个事务同时执行的时候，就可能出现
            脏读(dirty read)、
            不可重复读(non-repeatable read)
            幻读(phantom read)的问题，为了解决这些问题，就有了“隔离级别”的概念。
            
            脏读：是指在一个事务处理过程里读取了另一个未提交的事务中的数据。
            
            不可重复读：是指在一个事务里，多次读同一数据。在这个事务还没有结束时，另一个事务也访问该
                        同一数据。那么，在第一个事务中的两次读取数据之间，由于第二个事务的修改，那么
                        第一个事务两次读到的数据可能不一样的。这样就发生了在一个事务内两次的数据是不
                        一样的，因此称为不可重复读。    
            
            幻读：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，
                  这种修改涉及到表中的全部数据行。同时，第二个事务也修改了这个表中的数据，这种修改
                  是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改
                  的数据行，就好像发生了幻觉一样。
            
            
        隔离的越严实，效率就会越低。我们需要在二者之间寻找一个平衡点。
        SQL 标准的事务隔离级别包括：
            读未提交(read uncommitted)、
            读提交(read committed)、
            可重复读(repeatable read)、
            串行化(serializable)。
        
        读未提交是指：一个事务还没有提交时，它做的变更就能被别的事务看到。
        
        读提交是指：一个事务提交之后，它做的变更才会被其他事务看到。
        
        可重复读是指：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。
                    当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
        
        串行化：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。
               当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
               
                        
                     
        隔离级别        脏读（Dirty Read）     不可重复读（NonRepeatable Read）    幻读（Phantom Read）
        
        未提交读        可能                       可能                       可能

        已提交读        不可能                     可能                       可能

        可重复读        不可能                     不可能                     可能

        可串行化        不可能                     不可能                     不可能       
        
            
    2、 我们用一个例子说明几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，
        下面按照时间顺序执行两个事务的行为。
        
        mysql> create table T(c int) engine = InnoDB;
        insert into T(c) values (1);
        
        事务A:                            事务B:
        
        启动事务查询得到值 1               启动事务
        
                                         查询得到值 1 将 1 改成 2
                                           
        查询得到值 V1
        
                                         提交事务 B
                                         
        查询得到值 V2
        
        提交事务 A
        
        查询得到值 V3
        
        若隔离级别是“读未提交”，则 V1 的值就是 2。这个时候虽然还没有提交，但是结果已经被 A 看到了，
        因此，V2 和 V3 的值也都是 2。
        
        若隔离级别是“读提交”，则 V1 的值是 1，V2 的值是 2 。事务 B 的更新在提交后才能被 A 看到。
        所以，V3 的值也是 2。
        
        若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：
        事务在执行期间看到的数据前后必须是一致的。
        
        若隔离级别是“串行化”，则在事务 B 执行 “将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，
        事务 B 才可以继续执行，所以 A 的角度看，V1、V2 的值是 1， V3 的值是 2。
        
        
        在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。
        在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
        在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。
        在“读未提交”隔离级别下直接返回记录上的最新值，没有视图的概念。
        在“串行化”隔离级别下直接用加锁的方式来避免并行访问。
        
    3、配置方式：
    
        Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Orcal 迁移到 MySQL 的应用，
        为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”
        
        SELECT @@tx_isolation;  查看当前事务的隔离级别
        set session transaction isolation level read uncommitted; 设置事务的隔离级别
                
        mysql> SELECT @@tx_isolation;
        +-----------------+
        | @@tx_isolation  |
        +-----------------+
        | REPEATABLE-READ |
        +-----------------+
        1 row in set (0.02 sec)
        
        mysql> set session transaction isolation level read uncommitted;
        Query OK, 0 rows affected (0.02 sec)
        
        mysql> SELECT @@tx_isolation;
        +------------------+
        | @@tx_isolation   |
        +------------------+
        | READ-UNCOMMITTED |
        +------------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level read committed
            -> ;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                                
        +----------------+
        | @@tx_isolation |
        +----------------+
        | READ-COMMITTED |
        +----------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level repeatable read;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                                  
        +-----------------+
        | @@tx_isolation  |
        +-----------------+
        | REPEATABLE-READ |
        +-----------------+
        1 row in set (0.00 sec)
        
        mysql> set session transaction isolation level serializable;
        Query OK, 0 rows affected (0.00 sec)
        
        mysql> SELECT @@tx_isolation;                               
        +----------------+
        | @@tx_isolation |
        +----------------+
        | SERIALIZABLE   |
        +----------------+
        1 row in set (0.00 sec)
        
        
        总结来说，存在即合理，那个隔离级别都在自己的应用场景。
        “可重复读”隔离级别就很方便，事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
        
    4、事务隔离实现：
    
        在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。
        记录上的最新值，通过回滚操作，都可以得到前一个状态的值。                                                      
        当没有事务用的回滚日志时，回滚日志会被删除。
        
        基于上面情况，不建议使用长事务，长事务意味着系统里面会存在很老的事务视图。
        由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库
        里面它可能用到回滚记录都必须保留，导致大量占用存储空间。
        
    5、事务的启动方式：
        
        MySQL 的事务启动的几种方式：
        
        a、显式启动事务语句，begin 或 start transaction。配套的提交语句是 commit，回滚语句 rollback。
            
        b、set autocommit = 0, 这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句
            这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句
            或者断开连接。
            
        c、有些客户端连接默认链接成功后先执行set autocommit = 0 的命令，这就导致了接下来的查询都在事务中，
            如果是长连接，就导致了意味的长事务。
            
        建议使用： set autocommit = 1, 通过显式语句的方式启动事务。
        
        你可以在 infomation_schema 库的 innodeb_trx 这个表中查询长事务，比如下面语句，查找超过60s 的事务：
        
        select *from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;            
        
        mysql> select *from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60; 
        ERROR 1227 (42000): Access denied; you need (at least one of) the PROCESS privilege(s) for this operation
        mysql> 
        mysql> 
        mysql> desc information_schema.innodb_trx; 
        +----------------------------+---------------------+------+-----+---------------------+-------+
        | Field                      | Type                | Null | Key | Default             | Extra |
        +----------------------------+---------------------+------+-----+---------------------+-------+
        | trx_id                     | varchar(18)         | NO   |     |                     |       |
        | trx_state                  | varchar(13)         | NO   |     |                     |       |
        | trx_started                | datetime            | NO   |     | 0000-00-00 00:00:00 |       |
        | trx_requested_lock_id      | varchar(81)         | YES  |     | NULL                |       |
        | trx_wait_started           | datetime            | YES  |     | NULL                |       |
        | trx_weight                 | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_mysql_thread_id        | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_query                  | varchar(1024)       | YES  |     | NULL                |       |
        | trx_operation_state        | varchar(64)         | YES  |     | NULL                |       |
        | trx_tables_in_use          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_tables_locked          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_lock_structs           | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_lock_memory_bytes      | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_rows_locked            | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_rows_modified          | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_concurrency_tickets    | bigint(21) unsigned | NO   |     | 0                   |       |
        | trx_isolation_level        | varchar(16)         | NO   |     |                     |       |
        | trx_unique_checks          | int(1)              | NO   |     | 0                   |       |
        | trx_foreign_key_checks     | int(1)              | NO   |     | 0                   |       |
        | trx_last_foreign_key_error | varchar(256)        | YES  |     | NULL                |       |
        | trx_adaptive_hash_latched  | int(1)              | NO   |     | 0                   |       |
        | trx_adaptive_hash_timeout  | bigint(21) unsigned | NO   |     | 0                   |       |
        +----------------------------+---------------------+------+-----+---------------------+-------+
        22 rows in set (0.05 sec)

"""04| 深入浅出索引 (上)"""
    
    简单来说：索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。
  
    1、索引的常见模型
    
        索引的出现时为了提高查询效率，但是实现索引的方式却有很多中，索引就引入了索引模型的概念。
        最常见的三种：哈希表、有序数组、搜索树
        
        哈希表：
            
            哈希表是一种以 键-值(key-value)存储数据的结构，
            所以哈希表这种结构适用于只有等值查询的场景。
            比如 Memcached 及其他一些 NoSQL 引擎。
        
        有序数组：
            
            有序数组在等值查询和范围查询场景中的性能都有非常优秀。
            里面是存储的数据是顺序排序的，用二分法进行查找，时间复杂度 O(log(N))。
            如果仅仅看查询效率，有序数组就是最好的数据结构，但是，在需要更新数据的
            时候就非常麻烦了，你往中间插入一个记录就必须的挪动后面的所有记录，成本太高。
            所以，有序数组索引只适用于静态存储引擎，里面的数据不会修改。
        
        二叉树：   
            
            二叉搜索树特点：左节点小于父节点， 父节点小于右节点。
            二叉搜索树的时间复杂度是 O(logN), 更新复杂度也是 O(logN)。
            
            二叉树是搜索效率最高的，但是实际上大多数数据库存储并不使用二叉树，
            其原因，搜索不止存在内存中，还有写到磁盘上。
            
            你可以想象一下一颗 100 万节点的平衡二叉树，树高 20，一次访问需要访问 20 个数据块。
            单独访问一行可能需要 20 个 10 ms 的时间。查询很慢。
            
            为了让一个查询尽量少第读磁盘，必须让查询过程尽量少的数据块。那么
            我们不应该使用 二叉树，而是应该使用 "N 叉"树。这里“N叉”树的 N 取决于数据块大小。
            
            N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用到数据库引擎中。
            
            
    2、MySQL 中，存储引擎的实现，InnoDB的索引模型：           
        
        在 MySQL 中，索引是在存储引擎层实现的，所以没有统一的标准，不同的存储引擎索引的工作方式并不一样。
        
        在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。
        InnoDB 使用了 B+ 树索引模式，所以数据都是存储在 B+ 树中的。
        
        每一个索引在 InnoDB 里面对应一颗 B+ 树。
        
        假设，我们有一个主键列为 ID 的表，表中有字段 k, 并且在 k 上有索引。
        
        这个表的建表语句是：
        
            mysql> create table T(
            id int primary key,
            k int not null,
            name varchar(16),
            index(k))engine=InnoDB;    
        
        索引类型分为主键索引和非主键索引。
        
        主键索引的叶子节点存的是正行数据。在 InnoDB 里，主键索引也被称为聚簇索引(clustered index)。
        非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引页被称为二级索引(secondary index)。
        
        基于主键索引和普通索引的查询有什么区别？
            
            a. 如果语句是 select *from T where ID=500,即主键查询方式，则只需要搜索 ID 这颗 B+ 树。
            
            b. 如果语句是 select *from T where k = 5,即普通索引查询方式，则需要先搜索 k 索引树，得到
                ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。
                
        也就是说，基于非主键索引的查询需要多扫描一次索引树，因此，应尽量使用主键查询。
        
    3、索引维护：
    
        B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。
        
        你可能在一些建表规范里面见过类似的描述，要求建表的语句里一定要有自增主键。
        当然，事务绝对，我们分析一下，那些场景需要使用自增主键，而那些场景不应该。
                    
        自增主键是指自增序列上定义的主键，在建表语句中一般是这么定义的：NOT NULL PRIMARY KEY AUTO_INCREMENT.
        插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 的最大值加 1 作为下一条记录的 ID 值。
        
        也就是说，自增主键的插入数据模式，正符合递增插入模式的场景。每次插入一条新的记录。
        都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
        而又业务逻辑的字段做主键，则往往不容易保证有序插入，这些写数据成本性对较高。
        
        显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用空间也就越小。
        所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。
        
        有没有什么场景适合用业务字段直接做主键的呢？
        还是有的，比如，有些业务的场景需求是这样的：
            a. 只有一个索引。
            b. 该索引必须是唯一索引。
        
        你一定看的出来，就是典型的 KV 场景。
        由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。
        这时候要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，
        可以避免每次查询需要搜索两颗树。
            
                       
"""05| 深入浅出索引 (下)"""           
        
        
        
        
        
        
        
        
        
        
        
        
        
        
                    
                   
        
        
            
            
        
               
        
            
    
        
        
















    