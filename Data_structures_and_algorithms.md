"-------------------------------------------------------------------"
            
            学习极客时间王争老师《数据结构和算法之美》学习笔记   
            
"--------------------------------------------------------------------"

"""01: 为什么要学习数据结构和算法 """

    程序员所谓的瓶颈期其实是你自己是不是跟着行业在发展，还是每个项目都在重复
    的堆砌业务逻辑，没有难度递进，没有任何提升，十年和一年也没有什么区别。
    
    我们学习数据结构和算法，并不是为了死记硬背几个知识点，我们的目的是建立时间复杂度、
    空间复杂度意识、写出高质量的代码、能够设计基础架构、提升编程技能，训练逻辑思维。


"""02: 如何抓住重点，系统高效地学习数据结构和算法 """
    
    1、什么是数据结构和算法：
    
        从广义上讲：
        
            数据结构就是指一组数据的存储结构，算法就是操作数据的一组方法。
        
        从狭义上讲：
            
            指某些著名的数据结构和算法，比如，队列、栈、队、二分查找、动态规划等。
            
    2、数据结构和算法什么关系：
    
        数据结构和算法是相辅相成的，数据结构是为算法服务的，算法要作用在特定的数据结构之上。
        
    3、学习的重点在什么地方：
    
        学习数据结构和算法，首先要掌握一个数据结构和算法中最重要的概念--- 复杂度分析。
        
        10 个数据结构：
        
            数组、链表、栈、队列、三列表、二叉树、堆、跳表、图、Trie 树
            
        10 中算法：
        
            递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符匹配算法。
            
    4、小结：
    
        知识需要沉淀、不要试图一下子掌握所有。
        学习知识的过程是反复迭代，不断沉淀的过程。
        边学边练、多闻多思
        
        
"""03:  复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗"""

    数据结构和算法本身解决的是 "快" 和 "省" 的问题，及如何让代码运行得更快，如何让代码更省存储空间。
    所以，执行效率是算法一个非常重要的考量指标。
    
    复杂度分析是整个算法学习的精髓，只要掌握它，数据结构和算法的内容就基本上掌握了一半。
    
    1、为什么需要复杂度分析:
        
        摆脱一些客观因素的影响，我们需要一个不用具体的测试数据来测试，就可以粗略的估计算法
        的执行效率的方法。就是我们今天要讲的时间、空间复杂度分析方法。
        
    2、大 O 复杂度表示法：

        所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。
        
        我们可以把这个规律总结成一个公式：
         
            T(n) = O(f(n))
        
            其中： T(n) : 是代码执行的时间
                   n   : 表示数据规模的大小
                  f(n) : 表示每行代码执行的次数总和。
                  O    : 表示代码执行时间 T(n) 与 f(n) 表达式成正比。
            
            大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随
            数据规模增长的变化趋势，所以，也叫作渐进时间复杂度，简称"时间复杂度"。
   
    3、 时间复杂度分析：
           
        （1） 只关注循环执行次数最多的一段代码
            大 O 这种复杂度表示方法只是一种变化趋势，我们通常会忽略掉公式中的常量、低阶和系数
            只需要记录一个最大阶的量级就可以了，所以，我们在分析一个算法、一段代码的时间复杂度的时候
            也只关注循环执行次数最多的那段代码就可以了。
            
        （2） 加法法则：总复杂度等于量级最大的那段代码的复杂度。
       
        （3） 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
        
    4、几种常见时间复杂度实例分析：
    
        常量阶： O(1)
            
            O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。
            比如：下面代码有三行，他的时间复杂度为O(1) 而不是O(3)
                int i = 8
                int j = 6
                int sum = i + j
            
            只要代码执行时间不随 n 的增大而增大，这样的时间复杂度都记作 O(1).
            或者，一般情况下，只要算法中不存在循环语句、递归语句、即使有上千万行的代码
            其中的时间复杂度也是O(1)。
       
        对数阶： O(logN)、O(nlogn):
            
            如下面一段代码片段：
            
                i = 1;
                while (i <= n){
                    i = 2 * i
                }
                
            第三行代码是循环执行次数最多的，所以，我们只要计算出这行代码被执行了多少次，就能知道
            整段代码的时间复杂度。
            从代码可以看出，变量 i 的值从 1 开始取，每循环一次乘以 2。当大于 n 时，结束循环。
            2^x = n 求解 x 的值就是这段代码执行的次数。 x = log2n，所以代码的时间复杂度是O(log2n)
                
                i = 1
                while (i <= n){
                    i = i * 3
                }    
            上面这段代码的时间复杂度是 O(log3N)
           
            实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们都可以记为 O(logn)
                log3N = log32 * log2N,所以 O(log3N)=O(C * log2N) 其中 c = log32 是个常量。
            因此在对数阶时间复杂度的表示法我们忽略"底"，统一为 O(logN)
            
            如果一段代码的时间复杂度是 O(logN),我们循环执行 n 遍，时间复杂度就是 O(nlogN)了。
            快速排序和归并排序时间复杂度都是 O(nlogN)
               
        3、O(m + n)、O(m*n)
            
            有两个数据规模的复杂度。
            
            int cal(int m, int n){
                
                int sum_1 = 0;
                int i = 1;
                for(; i < m; ++i){
                    sum_1 = sum1 + i
                }
                int sum_2 = 0;
                int j = 1;
                for(; j < n; ++j){
                    sum_2 = sum_2 + j;
                }
                return sum_1 + sum_2;    
            }
            
            从代码看出，m 和 n 是代表两个数据规模，我们无法先评估 m 和 n 谁的量级大，所以我们
            表示复杂度的时候，就不能简单地利用加法法则，省略其中的一个。
            上面代码的时间复杂度是 O(m + n)
    
        线性阶： O(n)
        平方阶、立方阶、。。K次方阶：O(n^2)、O(n^3)、O(n^K)
        指数阶：O(2^n)
        阶乘阶：O(n!)
        
    5、 空间复杂度分析：
    
        时间复杂度的全称是：渐进时间复杂度，表示算法的执行时间与数据规之一个之间的增长关系。
        空间复杂度的全称是：渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。
        
        void print(int n){
            int i = 0;
            int [] a = new int[n];
            for(i; i<n;i++){
                a[i] = i * i
            }
            
            for(i = n-1; i>=0; --i){
                print out a[i]
            }
        }
        
        跟时间复杂度一样，第二行代码中，我们申请了一个空间存储变量 i,但是它是常量阶的，跟数据规模 n 没有关系。
        所以我们可以忽略。第三行申请一个大小为 n 的 int 类型数组，除此之外，剩下的代码里没有占用更多空间，
        多以整段代码的空间复杂度是 O(n)
        我们常见的空间复杂度是 O(1), O(n), O(n^2), 像 O(logN),O(nlogN)这样对数阶的复杂度平时用不到。
        
    6、小结：
    
        复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系。
        
        
"""04: 复杂度分析（下）： 浅析最坏、最好、平均、均摊时间复杂度"""        
        
    1、最好、最坏情况时间复杂度：（best/worst case time complexity）
        
        # n 表示数组 array 的长度
        int find(int [] array, int n, int x){
            int i = 0;
            int pos = -1;
            for(; i<n; ++i){
                if (array[i] == x) pos = i;
            }
            return pos;
        }
        
        # n 表示数组 array 的长度
        
        int find(int[] arrar, int n, int x){
            int i = 0;
            int pos = -1;
            for(; i < n; ++i){
                if (array[i] == x){
                    pos = i;
                    break;
                }
            }
            return pos;
        }       
            
        因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查询的变量 x
        那么就不需要遍历剩下的 n - 1 个数据了，那时间复杂度就是O(1), 如果数组中不存在，就需要
        把整个数组遍历一遍，时间复杂度就是 O(n)。不同情况，时间复杂度不同。
        
        为了表示代码在不同情况下不同时间复杂度，我们需要引起三个概念：最好情况时间复杂度、最坏情况时间复杂度和
        平均情况时间复杂度。
        
        平均情况时间复杂度:
            最好情况和最坏情况时间复杂度都是极端情况下的代码复杂度，发生的概率并不大。为了更好的表示
            平均情况下的复杂度，我们引入了另一个概念：平均情况复杂度，简称平均复杂度。
            
            要查找变量 x 在数组中的位置， 有 n + 1 种情况：在数组的 0 ~ n-1 位置中和不在数组中。
            我们把每种情况，查找需要遍历的元素个数累加起来，然后再除以 n + 1，就可以得到需要的元素个数
            的平均值 (1+2+3+...+n+n)/(n+1) = n(n+3)/2(n+1) 时间复杂度的大 O 标记法中，可以省略掉系数
            低级和常量，因此得到的时间复杂度是 O(n)
    
    2、均摊时间复杂度：
    
        # array 表示一个长度为 n 的数组
        # 代码中的 array.length 就等于 n
        
        int[] array = new int[n];
        int count = 0;
        void insert(int val){
            if (count == array.length){
                int sum = 0;
                for(int i=0; i< array.length; ++i){
                    sum = sum + array[i];
                }
                array[0] = sum;
                count = 1;
            }
            array[count]= val;
            ++count;
        }
        
        均摊时间复杂度就是一种特殊的平均时间复杂度。

"""数组：为什么很多编程语言中数组都是从0开始编号"""

    1、如何实现随机访问？
        
        数组（array）：是一种线性表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。
        线性表：就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。
                除了数组，链表、队列、栈等也是线性表结构。
                而与线性表对立的概念是非线性表，比如二叉树、堆、图等，在非线性表中，数据之间并不是简单的前后关系。
        
        连续的内存空间和相同类型的数据，正是因为这两个限制，它才有一个“杀手锏”的特性：“随机访问”。
        但是有利有弊，这两个限制也让数组的很多操作变得低效，比如插入和删除。
        
        计算机给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问
        数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素的内存地址：
        
                a[i]_address = base_address + i * date_type_size
                
                其中：base_address 内存块首地址
                     data_type_size 存储数据类型的大小
                     i  数组中的第几个数据
        
        数组是适合查找操作，但是查找的时间复杂度并不为 O(1)，即便是排好序的数组，采用二分法
        时间复杂度也是 O(logn),数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。
        
    2、低效的插入和删除：
    
        插入操作：
        
            假设数组的长度为 n , 如果数组在末尾插入时间复杂度为 O(1),
            在数组的开头插入时间复杂度为O(n),平均时间复杂度为 O(n).
            如果数组是有序的，我们在某个位置插入一个新的元素，就必须
            搬移 k 之后的数据。但是如果数组中的数据并没有任何规律，数组只是被当做一个存储
            数据的集合，在这种情况下，我们可以避免搬迁数据，直接将第 k 位的数据搬迁到数组
            末尾，将新的元素放入到第k个位置。
        
        删除操作：
        
            如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬迁数据，不然中间
            会出现空洞，内存就不连续了。
            和插入类似，末尾删除最好情况时间复杂度O(1),删除头数据时间复杂度为O(n),平均也是O(n)。
            
    3、警惕数组的访问越界问题：
        在 c 语言中只要不是访问受限的内存，所有的内存空间都是可以访问的。
        
    4、容器能否完全替代数组：
    
        对于业务开发，直接使用容器就足够，省时省力，毕竟损耗一丢丢性能，完全不会影响到整个系统整体性能，
        但是，如果做非常底层的开发，比如网络框架，性能的优化需要做到极致，这个时候数组优于容器。
 
    5、为什么数组从 0 开始编号，而不是从 1 开始呢：
    
        从数组的存储的内存模型上看，“下标”最确切的定义应该是“偏移（offset）”
        如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，
        a[k] 就表示偏移为 k 个type_size 的位置，所以计算a[k]的内存地址只需要
        用给这个公式：
            a[k]_address = base_address + k * type_size
            
        如果从 1 开始编号，计算数组元素 a[k]的内存地址会变为：
            a[k]_address = base_address + (k - 1)*type_size
            
        对比两个公式，从 1 开始编号，你每次随机访问数组元素都会多了一次减法运算，
        对于 CPU来说，就是多了一次减法指令。
        
        数组作为分成基础的数据机构，通过下标随机访问数组又是非常基础的编程操作，
        效率的优化要做到极致，所以数组选择从 0 开始编号。
        
        二维数组的内存寻址方式：
        
            对于 m * n 的数组，a[i][j](i<m, j<n)的地址为：
            
             address = base_address + (i*n + j) * type_size
           
           
"""06 链表（上）：如何实现LRU缓存淘汰算法"""        
    
    缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有广泛的应用，比如 cpu 缓存、数据库缓存、浏览器缓存等。
    
    缓存的大小有限、当缓存被用满时，那些数据应该被清理出去，那些数据应该被保留？这需要缓存淘汰策略来决定。
    常见的三种策略：先进先出策略 FIFO(First In, First Out)、最少使用策略 LFU(Least Frequently Used)
    最近最少使用策略 LRU(Least Recently Used)。
    
    1、数组和链表：
    
        数组：一块连续的内存空间来存储，对内存要求比较高。
             数组的删除和插入操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是O(n)
             
            
        
        链表：通过“指针”将一组零散的内存块串联起来使用，我们把内存块称为“结点”。为了将所有的结点串联起来，
              每个结点上除了保持数据之外还有保持下一个结点的地址，我们把下一个记录下一个结点的地址的指针
              叫作后继指针 next。
              链表的插入和删除操作，只需要考虑相邻结点的指针改变，多对应的时间复杂度是O(1)
              链表要访问第 k 个元素，就没有数组那么高效，因为链表中的数据并非连续存储的，
              所以无法像数组那样，通过指针和下标，通过寻址公式就能计算出对于的内存地址，
              而链表需要一个结点一个结点地依次遍历，直到找到相应的结点。时间复杂度O(n)
              
        循环链表：
    
            循环链表的优点是从链尾到链头比较方便，当要处理的数据具有环形结构特点时，就特别适合采用循环链表。
        
        双向链表：          
              
            双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。双向链表比单向链表占用更大的内存空间。
            但是支持双向遍历，操作更灵活。
    
    2、单向链表和双向链表
            
        双向链表适合解决那些问题？
            
            从结构上看，双向链表可以支持 O(1)的时间复杂度的情况下找到前驱结点，这是这样的特点，也使得
            双向链表在某些情况下的插入、删除操作都比单链表简单、高效。
            单链表的插入和删除操作时间复杂度已经是 O(1)了，双向链表还能再怎么高效呢？
                
            删除操作：
                在实际的开发中，从链表中删除一个数据无外乎两种情况：
                    （1）删除结点中“值等于某个给定值”的结点
                    （2）删除给定指针执向的结点。
                        
                对于第一种情况，无论是单链表还是双链表，为了查找值等于给定的结点，都需要从头结点开始
                一个一个依次遍历对比，直到直到的值等于给定的值的结点，然后通过指针操作将其删除。
                尽管单纯的删除操作时间复杂度是 O(1),单遍历查找的时间是主要的耗时点，对应的时间复杂度是O(n)。
                    
                对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表
                不支持直接获取前驱结点，所以要找到前驱结点需要从头开始遍历，直到 p->next = q,说明 p 是 q 的前驱结点。
                但是对于双向链表这是明显的优势。
                第二种情况单链表删除的时间复杂度是 O(n),双向链表是 O(1)
                
            插入操作：    
                             
                同理，希望在链表的某个结点的某个指定结点前面插入一个结点，双向链表的时间复杂度是O(1)，单向链表是O(n)。    
                  
            查询操作：
                    
                对于一个有序的链表，双向链表的按值查询的效率也要比单链表更加高一些，因为，我们可以记录上一次查询的位置 p,
                每次查询时，根据要查找的值与 p 的大小，决定是往前查找还是往后查找。
                    
        在实际的开发中虽然双向链表更费内存，但是比单向链表应用更广泛，java 中的 LinkedHashMap 容器就是用的双向链表。
                    
    3、用空间换时间的设计思想：
    
        当内存空间充足的时候，如果我们更加追求代码的执行速度，我们可以选择空间复杂度相对较高，
        时间复杂度相对比较低的算法或数据结构，相反，如果内存比较紧缺，比如代码在手机或者单片机上
        这个时候，反过来要从时间换空间的设计思想。
        
        缓存实际上就会说利用空间换时间的设计思想，如果把数据存储在硬盘上，回比较节省内存，单每次查查比较
        慢，如果用缓存技术，事先把数据加载到内存中，虽然会比较消耗内存空间，但是每次数据查询的速度就大大提高。
        
        内存充足（时间换空间），内存不足（空间换时间）
        
    4、链表 VS 数组：
        
        数组和内存是两种截然不同的内存组织方式，正是因为内存存储的区别，他们插入、删除、随机访问操作的时间复杂度正好相反。
        
        不过数组和链表对比，并不能局限于时间复杂度。在实际开发中，不能仅仅利用时间复杂度分析来决定使用哪个数据结构。
        数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。
        链表在内存中不是连续存储所以对 CPU 不友好，没办法有效预读。
        
        数组的确定是大小固定，一经声明就要占用整块连续内存空间。如果声明数组过大，系统可能没有足够的内存空间分配给它，
        导致“内存不足（out of memory）”。声明过小，则可能出现不够用的情况，这时只能申请一个更大的内存空间，把原来数据
        拷贝进去，非常费时。
        链表本身没有大小的限制，天然支持动态扩容。
        
        如果你的代码对内存使用很苛刻，那数组更适合你，因为链表中的每个结点都需要消耗额外的存储空间去存储一份执向下一个结点
        的指针，所以内存消耗会翻倍，而且，对链表进行频繁的插入、删除操作，导致频繁的内存申请和释放，容易造成内存碎片
        如果是java 语言，就可能导致频繁的GC。
        
        实际开发中要根据具体情况，权衡究竟是选择数组还是链表。
        
    5、如何基于链表实现 LRU 缓存淘汰算法。
    
        我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，
        我们从链表头开始顺序遍历链表。
        （1）如果此数据已经被缓存在链表中了。我们遍历得到这个数据对于的结点，并将其从原来的位置删除，然后插入到表头。
        （2）如果此数据没有在缓存链表中，又可以分为两种情况：
            如果此时缓存未满，则将此节点直接插入到链表头。
            如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。
                
        现在缓存访问的时间复杂度为 O(n).
        可以引入散列表来记录每个数据的位置，将缓存的访问时间复杂度降到 O(1).
        
        
"""07 链表（下）：如何轻松的写出正确的链表代码"""   
    
    1、理解指针或引用的含义：
    
        将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针存储了
        这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
        
    2、警惕指针丢失和内存泄露：
    
        如一个单链表，--->a--->b--->c--->d , 我们希望在结点 a 和相邻的结点 b 之间插入结点 x,
        假设当前指针 p 指向结点 a, 如果我们将代码实现成下面这个样子，就会发生指针丢失和内存泄露。
        
            （1）p->next = x; //将 p 的 next 指针指向 x 结点。
            （2）x->next = p->next; // 将 x 的结点的 next 指针指向 b 结点。
            
            p->next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x .
            第二行代码相当于将 x 赋值给 x ->next,自己指向自己，因此，整个链表就断成两半。
            从结点 b 往后的多有结点都无法访问到。
            
        对于 c 语言，内存管理是由程序员负责，如果没有手动释放对应的内对应存空间，就会产生内存泄露。
        所以，我们插入结点时，一定要注意操作的顺序，同理，删除链表结点时，也一定要记得手动释放内存空间。
        
    3、利用哨兵简化实现难度：
    
        插入一个新结点:  
            new_node->next = p->next;
            p->next = new_node;
            
            如果是空链表上面的逻辑就不能用：
                if(head == null){
                    head = new_node
                }
            
        删除一个结点：
        
            p->next = p->next->next;
            
            如果我们删除的是最好一个结点，上面代码就不能使用：
                if(head->next == null){
                    head = null
                }
                
        针对链表的插入和删除操作，需要对插入第一个结点和删除的最后一个结点的情况进行特殊处理。
        
        还记得如何表示一个空链表吗？ head = null 表示链表中没有结点了，其中 head 表示头结点指针，指向链表的第一个结点。
        
        如果们引入哨兵结点，在任何时候不管链表是不是空，head 指针都会一直指向这个哨兵结点。
        我们也把也把有哨兵结点的链表叫作带头链表，相反，没有哨兵结点的链表叫作不带头链表。
        
        哨兵结点时不存储数据的，因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和
        删除其他结点，都可以统一为相同的代码实现逻辑。
                          
        代码一：
        
            //在数组 a 中，查找 key, 返回 key 所在是位置
            // 其中， n 表示数组 a 的长度。
            
            int find(char *a, int n, char key){
                
                // 边界处理，如果 a 为空，或者 n <=0,说明数组中没有数据，就不用进行下面的循环了。
                if(a == null || n <= 0){
                    return -1;
                }
                
                int i = 0;
                //这里有两个比较操作：i < n 和 a[i] = key
                while(i < n){
                    if(a[i] == key){
                        return i;
                    }
                    ++i;
                }
                return -1;
            }
            
            
        代码二：
        
            int find(char *a, int n, char key){
                if(a == null || n<=0){
                    return -1;
                }
                
                if(a[n-1] == key){
                    return n-1;
                }
                
                char tmp = a[n-1];
                a[n-1] =  key;
                int i = 0;
                while(a[i] ! = key){
                    ++i;
                }
                
                a[n-1] = temp;
                
                if(i == n-1){
                    return -1;
                }else{
                    return i;
                }
            }    
            
       对比两段代码，在字符串 a 很长的时候，比如 几十万，代码二执行更快，因为两段代码执行次数最多的是
       while 循环中的部分，第二段我们通过一个哨兵 a[n-1] = key,成功省略掉一个比较语句 i < n,
       不要小看这一条语句，当累计万次时，积累的时间很明显了。
       
    4、重点留意边界条件处理：
    
        用来检查链表代码是否正确的边界条件有这样几个：
        
            （1）如果链表为空时，代码是否能正常工作？
            （2）如果链表只包含一个结点时，代码是否能正常工作？
            （3）如果链表只包含两个结点时，代码是否能正常工作？
            （4）代码逻辑在处理头结点和尾结点时候，是否能正常工作。
            
    5、举例画图，辅助思考：
    
    6、多写多练，没有捷径：
    
        5个常见的链表操作
            单链表翻转
            链表中环的检测
            两个有序的链表合并
            删除链表倒数第n 个结点
            求链表的中间结点
       
        
    7、小结：
        
        写链表代码最考验逻辑思维能力。
     
     
"""08 栈：如何实现浏览器的前进和后退功能？""" 
    
    1、如何理解栈：
    
        栈：后进先出、先进后退
        从栈的操作特性上看：栈是一种“操作受限”的线性表，只允许一端插入和删除数据。
        
        相比数组和链表，栈给我带来了限制，并没有任何优势，那么我直接使用数组和链表好了，
        为什么还要使用“操作受限的栈”呢？
        
        事实上，从功能上说，数组或链表确实可以替代栈，但是，特定的数据结构是对特定场景的抽象，
        而且，数组和链表暴露太多的操作接口，操作上确实灵活，但是用时比较不可控，自然也就更
        容易出错。
        
        当某个数据集合只涉及从一端插入和删除数据，并且满足后进先出，先进后出的特性，我们就应该
        首先 “栈” 这种数据结构。
        
        实际上，栈既可以用数组实现，也可以用链表实现，用数组实现的叫顺序栈，用链表实现的叫链式栈。
        不管是顺序栈还是链式栈，我们存储数据只需要一个大小伟 n 的数组就够了。在入栈和出栈只需要
        一两个临时变量存储空间，所以空间复杂度是 O(1)
        
        注意：这里存数据需要一个大小为 n 的数组，并不是说空间复杂度就是 O(n),因为，这个 n 个空间
        是必须的，无法省略掉，所以我们说空间复杂度时，是指除了原本的数据存储空间外，算法运行还需要
        额外的存储空间。
        
    2、栈在函数调用中的应用：
    
        操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数
        调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当函数执行完成，返回
        之后，将这个函数对于的栈帧出栈。
            
            int add(int x, int y){
                
                int sum = 0;
                sum = x+y；
                return sum;
            }
        
            int main(){
                
                int a = 1;
                int ret = 0;
                int res = 0;
                ret = add(3, 5);
                res = a + ret;
                pirntf("%d", res);
                return 0;
            }
   
    3、 栈在表达式求值中的应用：
        
        编译器如何利用栈实现表达式求值。
        比如 34 + 13 * 9 + 44 - 12/3 编译器是如何实现求值的呢？
        
        实际上，编译器是通过两个栈来实现的，其中一个保存操作数的栈，另一个是保存运算符的栈。
        我们从左到右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符
        栈的栈顶元素进行比较。
        
        如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或相同，
        从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入
        操作数栈，继续比较。
        
         
    4、栈在括号匹配中的应用：
    
        除了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。
        
        假设三种括号（）、{}、[]，并且可以任意嵌套。现在给三种括号的表达式字符串，如何检查是否合法？
        我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；
        如果遇到右括号，从栈顶取出一个括号，如果能够匹配，则继续扫描剩余的字符串。如果在扫描过程中
        遇到不能匹配的右括号，或栈中没有数据，则说明为非法格式。
        
        当所有的括号都扫描完成之后，如果栈为空，说明字符串为合法字符串；否则，有未匹配的左括号为非法字符串。
        
    5、浏览器如何实现前进、后退功能：
    
        我们使用两个栈 X 和 Y, 我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 栈中出栈，
        并将出栈的数据依次放入栈 Y 。当我们点击前进按钮时，我们依次从 Y 栈中取数据放入 x 栈中。当 x 栈中
        没有数据，那数名没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。    
        
    6、内容小结：
    
        栈是一种操作受限的数据结构，只支持入栈和出栈操作。后进先出是它最大的特点。
        入栈和出栈的时间复杂度都是 O(1).       
   
    7、课后思考：
    
        （1）我们在将栈的应用时，讲到函数调用栈来保存临时变量，为什么函数调用"栈"来保存临时变量，
            用其他数据结构不行吗？
            
            答：因为函数调用的执行顺序符合后进者先出，先进者后出的特点。
                函数调用中经常嵌套，例子：A调用B，B又调用C，那么就需要先把C执行完，结果赋值给B中的临时变量，
                B的执行结果再赋值给A的临时变量，嵌套越深的函数越需要被先执行，这样刚好符合栈的特点，
                因此每次遇到函数调用，只需要压栈，最后依次从栈顶弹出依次执行即可，
                根据数据结构是特定应用场景的抽象的原则，我们优先考虑栈结构。
            
        （2） JVM 内存管理中有个 “堆栈” 的概念。栈内存用来存储局部变量和方法调用，
              堆内存用来存储 java 中的对象。那么 JVM 里面的“栈”和我们这里说的“栈”
              是不是一回事呢？如果不是，为啥都叫做“栈”呢？
            
            答：内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。
            内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。
            代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。
            静态数据区：存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量。系统自动分配和回收。
            栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。
            堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。    
            
              
        
"""队列：队列在线程池等有限资源池中的应用"""                  
        
    1、如何理解队列：
    
        先进先出，就是最基本的队列
        队列两个最基本的操作：入队（enquenue()）,放一个数据到队列尾部；出队（dequeue()）,从队列头取出一个元素。
        和栈一样，队列也是一种操作受限的线性表数据结构。
        
        作为一种非常基础的数据结构，队列的应用非常广泛，特别是一些具有额外特性的队列：
        比如：循环队列、阻塞队列、并发队列。
        
    2、顺序队列和链式队列：
    
        队列和栈一样，也是一种抽象的数据结构。它具有先进先出的特性，支持队尾插入元素，在对头删除元素。
        用数组实现的队列叫顺序队列，用链表实现的队列叫链式队列。
        
        用数组实现队列，随着不停是入队和出队操作，head 和 tail 往后移动，当 tail　移动到最右边，即使
        数组还有空闲空间（数组头的位置，因为head 出队不断后移），也无法继续往队列中添加数据了，
        这时就要进行数据搬移，迁移到一个更大的数组。
           
    3、循环队列：
        
        在 tail == n 时，会有数据搬移操作，这样入队操作性能就会受到影响，那么有没有一种办法能够避免
        数据搬移呢？看看循环队列的思路
        
        循环队列，顾名思义，它长得像一个环，原本数组有头为尾，是一条直线，现在我们把首尾相连。
        
        假设 队列大小为 8（0,1,2,3,4,5,6,7） ，当前head = 4， tail = 7，当有一个新的元素 a 入队时，我们放入下标
        为 7 的位置，我们并不是把 tail 更新为8，而是将其在环中后移以为，将移动到下标为 0 的位置。
        当再有一个元素 b 入队时，将 b 放入下标为 0 的位置，然后tail 加 1 更新为 1.
        通过这种方法，成功避免了数据搬移操作。
        
        最关键的时，确定好队空和对满的判断条件。
            
            在用数组的非循环队列中，队满的判断条件是 tail == n(数组大小)，队空的判断条件是（head == tail）
        
            循环队列，队空的判断条件依然是 head == tail，队列满的条件是 （tail + 1）%n = head.
            当对满时，tail 指向的位置实现上是没有存储数据的，循环队列会浪费一个数组的存储空间。
            
            
    4、阻塞队列和并发队列：
        
        阻塞队列其实就是在队列的基础上增加了阻塞操作。简单来说，就是队列为空的时候，
        从队头取数据会被阻塞，因为没有数据可取，直到队列中插入新的数据才能返回。
        队满的时候，插入数据操作会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。
        我们使用阻塞队列可以实现一个“生成者--消费者模式”
        
        并发队列：又叫线程安全队列，最简单直接的方法是 enqueue(),dequeue()方法上加锁，
        但是锁粒度大并发度会比较低，同一时刻仅允许一个存或取操作。
        实际上，基于数组的循环队列，利用了 CAS 原子操作，可以实现高效并发。
        
    5、线程池没有空闲线程时，新的任务请求资源时，线程池该如何处理，各种处理策略如何实现
    
        （1）非阻塞处理方式，直接拒绝任务请求
        （2）阻塞处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。
            队列正是这样数据结构来存储排队请求。
            基于链表的实现方式，可以支持一个无限的排队的无界队列，但是可能会导致
            请求排队等待，请求处理的相应时间过长。
            基于数组的有界队列的大小有限，所以线程池中排队的请求超过队列大小时，
            接下来的请求会被拒绝。
            
        实际上，对于大部分的资源有限场景，当没有空闲资源时，基本上都可以用“队列”这种、
        数据结构来实现请求排队。
        
    6、课后思考：
    
        （1）除了线程池结构用到队列排队请求，还有那些会用到队列排队请求？
            分布式中的消息队列，也是一种队列结构
        
        （2）如何实现无锁并发队列？
            无锁队列主要是通过CAS、FAA这些原子操作，和Retry-Loop实现。
            对于Retry-Loop，我个人感觉其实和锁什么什么两样。
            是这种“锁”的粒度变小了，主要是“锁”HEAD和TAIL这两个关键资源。而不是整个数据结构。
        
        
"""10 递归：如何用三行代码找到最终推荐人"""           
    
    数据结构和算法两个最难理解的知识点：动态规划和递归
    1、如何理解“递归”
        
        一个非常标准的递归求解问题的分解过程，去的那个过程叫“递”，回来的过程叫“归”。
        基本上所有的递归问题都可以用递推公式来表示。
        
        生活中的电影院第几排的例子，我们用递推公式将它表示出来就是：
        
            f(n) = f(n - 1) + 1 其中 f(1) = 1
         
            f(n) 表示想知道自己在哪一排，f(n-1) 表示前面一排所在的排数，f(1)表示第一排知道自己在第一个排。
            有了这个递推公式，我们很轻松递归代码：
            
            int f(int n){
                if(n == 1) return 1;
                return f(n - 1) + 1
            } 
            
    2、递归需要满足的三个条件：
    
        （1）一个问题的解可以分解为几个子问题的解。
            
            何为子问题？子问题就是数据规模更小的问题。
            
        （2）这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。
            
            例如上例中的，自己在那一排的思路和前面一排求解自己在哪一排的思路是一样的，
            就是 前排 + 1
            
        （3）存在递归终止条件。
            
            把问题分解为子问题，吧子问题再分解成子子问题，一层一层分解下去，不能存在无限循环
            这就需要终止条件，上例中的 f(1) = 1 就是终止条件  
                            
    3、如何编写递归代码：
        
        写递归代码的关键是写出递归公式，找到终止条件，剩下就是让递归公式转换成代码。
        
        假设有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问 走这 n 个台阶有多少中走法。
        如果有 7 个台阶，你可以 2，2，2，1 这样子走，也可以1， 2， 1， 1， 2 这样子走，那么
        如何用编程求得总共有多少中走法呢？
        
        仔细想想，实际上，可以根据第一步的走法把所有走法分成两类，第一类是第一步走 1 个台阶，
        另一类是第一步走了 2 个台阶。多以 n 个台阶的走法就是先走 1 阶后，n - 1 个台阶的走法
        加上先走 2 个阶后，n - 2 个台阶的走法。
        用公式表示就是：
                        f(n) = f(n - 1) + f(n - 2)
                        
        我们再看看终止条件，当有一个台阶时，我们不需要在继续递归，就只有一种走法，所以 f(1) = 1.
        还有f(2) = 2 作为一种终止条件，表示 2 个台阶，有两种走法，一步走完，或者分两步来走，
        所以，终止条件就是 f(1) = 1, f(2) = 2
        
        我们把递归终止条件和递归公式放在一起就是这样：
        
            f(1) = 1
            f(2) = 2
            f(n) = f(n-1) + f(n-2)
        
        有了这个公式，转成代码就简单多了，最终的代码公式是：
        
            int f(int n){
                if (n == 1) return 1;
                if (n == 2) return 2;
                return f(n - 1) + f(n - 2);
            }        
    
        写递归代码的关键是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式。
        然后再推敲最终条件，最终将递推公式和终止条件翻译成代码。
    
        如果递归调用只有一个分支，也就是说“一个问题只需要分解为一个子问题”我们很容易想清楚
        “递” 和 “归” 的每一个步骤，所以写起来和理解起来都不难。
        
        但是，当我们面对的是一个问题要分解成多个子问题的情况，递归代码就没有那么好理解。
        比如上面的例子。
    
    4、 怎样理解递归：    
        
        计算机擅长做重复的事情，所以递归正和它的胃口，而人脑喜欢平铺直叙的思维方式，当我们看到递归时，
        我们总想把递归平铺展开，脑子里就会循环，一层一层往下调，然后再一层一层返回，试图想搞清楚
        计算机每一步都是怎样执行的，这样就很容易被绕进去。
        
        对于递归代码，这种试图想弄清楚整个“递” 和 “归” 过程的做法，实际上有很多误区，很多时候
        理解起来比较吃力，主要是自己给自己造成的理解障碍，那正确的思维方式应该怎样？
        
        如果一个问题 A 可以分解为若干个字问题 B、C、D, 你可以假设子问题 B、C、D 都已经解决，
        在此基础上思考如何解决问题 A. 而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可。
        不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节。
        
        因此，编写递归代码的关键是，只要需要递归，我们就把它抽象成一个递推公式，不用想层层调用关系，
        不用试图用人脑去分解递归的每个步骤。
        递归代码要警惕堆栈溢出，指定要递归退出条件，我们可以在代码中限制递归调用的最大深度方式来解决。
        递归调用一定深度之后，我们就不继续往下再递归了，直接返回保错。
        
            int depth = 0;
            int f(int n){
                ++depth;
                if (depth >1000) throw exception;
                
                if(n == 1)return 1;
                return f(n - 1) + 1
            }
        
        
    5、递归代码要警惕重复计算：
    
        使用递归时还会出现重复计算的问题，比如刚刚我们把递归过程分解一下，
        f(6) = f(5) + f(4)
        f(5) = f(4) + f(3)
        f(4) = f(3) + f(2)
        .....
        
        从分析，我们可以直观看到，想要计算 f(5), 需要先计算 f(4) 和 f(3),
        而计算 f(4) 还需要计算 f(3), 因此 f(3) 就被计算很多次，这就是重复计算的问题。
        为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经解决过的 f(k).
        当递归调用到 f(k) 时，先看下是否求解过，如果是，则直接从散列表中取值返回，不需要
        重复计算，这样就避免刚刚讲过的问题。
        
        public int f(int n){
            
            if(n == 1) return 1;
            if(n == 2) return 2;
            
            if(hasSolvedList.containsKey(n)){
                return hasSovledList.get(n)
            }
            
            int ret = f(n - 1) + f(n - 2);
            hasSovedList.put(n, ret)
            return ret
        }
        
        除了堆栈溢出，重复计算这两个问题，递归代码还有很多别的问题。
        比如时间效率。  
           
    6、怎样将递归代码改写为非递归代码？
        
        递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；
        而弊端是空间复杂度高，有栈溢出风险、存在重复计算、过多的函数调用会耗时比较多问题。
         
   
        比如上面的两个例子：
        
            int f(int n){
                int ret = 1;
                for(int i = 2; i <= n; ++i){
                    ret = ret + 1;
                }
                return ret;
            }
            
        第二个例子：
        
            int f(int n){
                if (n == 1) return 1;
                if (n == 2) return 2;
                
                int ret = 0;
                int pre = 2;
                int prepre = 1;
                
                for(int i = 3; i <= n; i++){
                    ret = pre + prepre;
                    prepre = pre;
                    pre = ret;
                }
                return ret;
            }    
            
        是不是所有的递归代码都可以改为 迭代循环的非递归代码？
        笼统的说，是的，因为递归本身就是借助栈来实现的，不过我们使用的栈是系统或虚拟机本身提供的。
                 
    7、如何实现“最终推荐人”
    
        long findRootReferrerID(long actorId){
            Long referrerId = select referrer_id from [table] where actor_id = actorId;
            if (referrerId == null) retrun actorId;
            return findRootReferrerId(referrerId)
        }        
        
        两个问题：   递归很深时，可能会有栈溢出的问题
                    如果数据库存在脏数据，我们还要处理由此出现的无限循环问题如：a-b-c-a
    8、内容小结：
    
        递归时一种高效、简洁的编码技巧，只有满足“三个条件”的问题都可以通过递归代码来解决。
        递归有很多弊端：如 堆栈溢出、重复计算、函数调用耗时、空间复杂度高等问题。
        
        不过递归也难写、难理解。写递归正确的姿势是写出递推公式，找出终止条件，然后再翻译成递归代码。


"""11 排序(上)：为什么插入排序比冒泡排序更受欢迎"""                       
     
    插入排序和冒泡排序的时间复杂度都是 O(n^2), 在实际的软件开发里，为什么我们更倾向于使用
    插入排序算法而不是冒泡排序算法呢？
    
    1、如何分析一个“排序算法”
        
        学习排序算法，我们除了学习它的算法原理、代码实现外，更重要的是要学会如何评价，分析一个排序算法。
        那么分析一个排序算法，要从那几个方面入手？
        
        （1）排序算法的执行效率
            
            a. 最好情况、最坏情况、平均情况时间复杂度, 为什么要区分三种时间复杂度？
                第一，有些排序算法会区分，为了好对比，所以我们最好都做一下区分
                第二，对于要排序的数据，有些接近有序，有些完全无序，对于不同的数据排序的执行时间肯定是有
                    影响的，我们要知道排序算法在不同数据下的性能表现。
                
            b. 时间复杂度的系数、常数、低阶。
                时间复杂度反应的是数据规模 n 很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低级。
                我们排序 n 很小的时候，在对于同一阶时间复杂度排序算法性能对比的时候，我们要把系数、常数、低级考虑进来。
            
            c. 比较次数和交换（或移动）次数。
                
                基于比较的排序算法的执行过程，会涉及两种操作，一种是比较元素大小，另一种是元素交互或移动。
                所以，我们在分析排序算法的执行效率时，应该把比较次数和交换移动次数也考虑进去。
        
        （2）排序算法的内存消耗
        
                算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。
                不过，针对排序算法的空间复杂度，我们引入了一个新的概念，原地排序（Sorted in place）.
                原地排序就是指空间复杂度是 O(1) 的排序算法。
        
        （3）排序算法的稳定性
        
            稳定性是衡量排序算法的一个重要指标。
            稳定性：如果待排序的序列中存在的值相等，经过排序之后，相等元素之间原有的先后顺序不变。
            
            比如一组数据：2,9,3,4,8,3， 安照大小排序之后是2,3,3,4,8,9
            这组数据里有两个 3， 经过某种排序算法排序之后，如果两个 3 的前后顺序没有发生改变，
            那么，我们把这种排序算法叫做稳定的排序算法，否则就是不稳定排序算法。
            
            为什么要考察排序算法的稳定性呢？
                在真正的软件开发中，我们要排序的往往不是单纯的整数，而是一组对象，我们需要按照某个 key 来排序。
                比如说，我们现在要给电商交易系统中的“订单”排序，订单有两个属性，一个是下单时间，一个是金额。
                如果现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序，对应相同金额的订单，我们
                希望从下单的早到晚排序，我们改怎么做？
                
                有一种办法：先按照金额进行排序，然后，再遍历排序之后的订单数据，对于每个金额相同的小区间再按照
                下单时间排序。这种思路理解起来不难，但是实现起来很复杂。
                
                借助稳定的排序算法，这个问题可以非常简洁的解决。思路如下：
                    先按照下单时间进行排序，排序完成之后，我们使用稳定算法，按照金额大小重新排序。
                    两次排序之后，我们的订单数据是按金额重按大小排序，金额相同的订单按下单时间从早到晚排序。
                    
                    稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变，金额相同的订单仍然
                    保持下单时间从早到晚。
                    
    2、冒泡排序（bubble sort）：
        
        
    
              
                    
                
                    
                
            
                
                     
                            
        
         
            
        
    2、
                       
       
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        